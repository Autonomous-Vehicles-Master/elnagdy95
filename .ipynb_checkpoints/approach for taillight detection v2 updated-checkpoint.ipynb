{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import argparse\n",
    "import numpy as np\n",
    "import cv2\n",
    "#from scipy.misc import imresize\n",
    "#from moviepy.editor import VideoFileClip\n",
    "#from IPython.display import HTML\n",
    "from keras.models import load_model\n",
    "#from PIL import Image\n",
    "\n",
    "\n",
    "#argparser = argparse.ArgumentParser(\n",
    "    #description='test FCN8 network for taillights detection')\n",
    "\n",
    "\n",
    "#argparser.add_argument(\n",
    "    #'-i',\n",
    "    #'--image',\n",
    "    #help='path to image file')\n",
    "\n",
    "def auto_canny(image, sigma=0.33):\n",
    "    \n",
    "\n",
    "    # compute the median of the single channel pixel intensities\n",
    "    v = np.median(image)\n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv2.Canny(image, lower, upper)\n",
    "    # return the edged image\n",
    "    return edged\n",
    "\n",
    "\n",
    "# Load Keras model\n",
    "#model = load_model('full_CNN_model.h5')\n",
    "\n",
    "# Class to average lanes with\n",
    "#class Lanes():\n",
    "    #def __init__(self):\n",
    "        #self.recent_fit = []\n",
    "        #self.avg_fit = []\n",
    "\n",
    "def taillight_detect(image):\n",
    "    \"\"\" Takes in a road image, re-sizes for the model,\n",
    "    predicts the lane to be drawn from the model in G color,\n",
    "    recreates an RGB image of a lane and merges with the\n",
    "    original road image.\n",
    "    \"\"\"\n",
    "    model = load_model('full_CNN_model.h5')\n",
    "    #image1=image\n",
    "    #image1=np.array(image1)\n",
    "    #objects=np.squeeze(image,2)\n",
    "    #rows,cols=objects.shape\n",
    "    \n",
    "    rows, cols,_ = image.shape\n",
    "    \n",
    "    #cols, rows = image.size\n",
    "    #cols=160\n",
    "    #rows=80\n",
    "    # Get image ready for feeding into model\n",
    "    \n",
    "    small_img = cv2.resize(image, (160, 80))\n",
    "    \n",
    "\n",
    "    #img_y_cr_cb = cv2.cvtColor(small_img, cv2.COLOR_BGR2YCrCb)\n",
    "    #y, cr, cb = cv2.split(img_y_cr_cb)\n",
    "\n",
    "    # Applying equalize Hist operation on Y channel.\n",
    "    #y_eq = cv2.equalizeHist(y)\n",
    "\n",
    "    #clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    #y_eq = clahe.apply(y)\n",
    "\n",
    "    #img_y_cr_cb_eq = cv2.merge((y_eq, cr, cb))\n",
    "    #small_img = cv2.cvtColor(img_y_cr_cb_eq, cv2.COLOR_YCR_CB2BGR)\n",
    "\n",
    "    \n",
    "    #small_img = imresize(image, (80, 160, 3))\n",
    "    small_img = np.array(small_img)\n",
    "    small_img = small_img[None,:,:,:]\n",
    "\n",
    "    # Make prediction with neural network (un-normalize value by multiplying by 255)\n",
    "    prediction = model.predict(small_img)[0] * 255\n",
    "\n",
    "    #new_image = imresize(prediction, (rows, cols, 3))\n",
    "\n",
    "    mask = cv2.resize(prediction, (cols, rows))\n",
    "    \n",
    "    img_y_cr_cb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    y, cr, cb = cv2.split(img_y_cr_cb)\n",
    "\n",
    "    # Applying equalize Hist operation on Y channel.\n",
    "    #y_eq = cv2.equalizeHist(y)\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    y_eq = clahe.apply(y)\n",
    "\n",
    "    img_y_cr_cb_eq = cv2.merge((y_eq, cr, cb))\n",
    "    image_he = cv2.cvtColor(img_y_cr_cb_eq, cv2.COLOR_YCR_CB2BGR)\n",
    "    \n",
    "    gray = cv2.cvtColor(image_he, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    #auto = auto_canny(blurred)\n",
    "    auto = cv2.Canny(blurred, 10, 200)\n",
    "\n",
    "    #for i in range(rows):\n",
    "        #x = []\n",
    "        #for j in range(cols):\n",
    "            #k = gray[i,j]\n",
    "            #print(k)\n",
    "            #x.append(gray[i,j])\n",
    "        #print(x)\n",
    "    \n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if auto[i,j] >0 and mask [i,j]>10:\n",
    "                auto[i,j]=255\n",
    "            else:\n",
    "                auto[i,j]=0\n",
    "                \n",
    "    #cv2.imshow('histogram equalisation', auto)\n",
    "    #cv2.waitKey(0)\n",
    "    \n",
    "    #h, w = edges.shape[:2]\n",
    "    filled_from_bottom = np.zeros((rows, cols))\n",
    "    for col in range(cols):\n",
    "        for row in reversed(range(rows)):\n",
    "            if auto[row][col] < 255: filled_from_bottom[row][col] = 255\n",
    "            else: break\n",
    "    \n",
    "    filled_from_top = np.zeros((rows, cols))\n",
    "    for col in range(cols):\n",
    "        for row in range(rows):\n",
    "            if auto[row][col] < 255: filled_from_top[row][col] = 255\n",
    "            else: break\n",
    "    \n",
    "    filled_from_left = np.zeros((rows, cols))\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            if auto[row][col] < 255: filled_from_left[row][col] = 255\n",
    "            else: break\n",
    "    \n",
    "    filled_from_right = np.zeros((rows, cols))\n",
    "    for row in range(rows):\n",
    "        for col in reversed(range(cols)):\n",
    "            if auto[row][col] < 255: filled_from_right[row][col] = 255\n",
    "            else: break\n",
    "    \n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if filled_from_bottom[i,j] ==0 and filled_from_top[i,j]==0 and filled_from_right[i,j] ==0 and filled_from_left[i,j]==0:\n",
    "                auto[i,j]=255\n",
    "            else:\n",
    "                auto[i,j]=0\n",
    "    \n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    opening = cv2.morphologyEx(auto, cv2.MORPH_OPEN, kernel)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    cv2.imshow('histogram equalisation', closing)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    blanks = np.zeros_like(closing).astype(np.uint8)\n",
    "    lane_drawn = np.dstack((closing, blanks, blanks))\n",
    "    image = cv2.addWeighted(image, 1, lane_drawn, 1, 0)\n",
    "    \n",
    "    cv2.imshow('histogram equalisation', image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    #closing =  np.expand_dims(closing, 2) \n",
    "    #closing = np.repeat(closing, 3, axis=2) # give the mask the same shape as your image\n",
    "    #colors = {\"red\": [0.0,1.0,1.0], \"blue\": [0.,0.,0.1]} # a dictionary for your colors, experiment with the values\n",
    "    #colored_mask = np.multiply(closing, colors[\"red\"])  # broadcast multiplication (thanks to the multiplication by 0, you'll end up with values different from 0 only on the relevant channels and the right regions)\n",
    "    #image = image+colored_mask # element-wise sum (sinc img and mask have the same shape)\n",
    "    #cv2.imshow('histogram equalisation', image)\n",
    "    #cv2.waitKey(0)\n",
    "    \n",
    "\n",
    "    #return image.astype(float) / 255\n",
    "\n",
    "    #return new_image\n",
    "    #return auto\n",
    "    return image\n",
    "    \n",
    "#lanes = Lanes()\n",
    "\n",
    "# Where to save the output video\n",
    "#vid_output = 'proj_reg_vid.mp4'\n",
    "\n",
    "# Location of the input video\n",
    "#clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "\n",
    "#vid_clip = clip1.fl_image(road_lines)\n",
    "#vid_clip.write_videofile(vid_output, audio=False)\n",
    "\n",
    "#def _main_(args):\n",
    "    #image_path   = args.image\n",
    "\n",
    "\n",
    "#im = cv2.imread(\"ft.png\")\n",
    "#detected=taillight_detect(im)\n",
    "\n",
    "\n",
    "#cv2.imwrite('detected.jpg',detected)\n",
    "\n",
    "\n",
    "\n",
    "image = cv2.imread(\"ft5.png\")\n",
    "\n",
    "x=taillight_detect(image)\n",
    "\n",
    "#cv2.imshow('histogram equalisation', x)\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "#img_y_cr_cb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "#y, cr, cb = cv2.split(img_y_cr_cb)\n",
    "\n",
    "    # Applying equalize Hist operation on Y channel.\n",
    "    #y_eq = cv2.equalizeHist(y)\n",
    "\n",
    "#clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "#y_eq = clahe.apply(y)\n",
    "\n",
    "#img_y_cr_cb_eq = cv2.merge((y_eq, cr, cb))\n",
    "#image = cv2.cvtColor(img_y_cr_cb_eq, cv2.COLOR_YCR_CB2BGR)\n",
    "\n",
    "#gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "# apply Canny edge detection using a wide threshold, tight\n",
    "# threshold, and automatically determined threshold\n",
    "\n",
    "#wide = cv2.Canny(blurred, 10, 200)\n",
    "#tight = cv2.Canny(blurred, 225, 250)\n",
    "#auto = auto_canny(blurred)\n",
    "\n",
    "# show the images\n",
    "#cv2.imshow(\"Original\", image)\n",
    "#cv2.imshow(\"Edges\", np.hstack([wide, tight, auto]))\n",
    "#cv2.waitKey(0)\n",
    "#rows,cols = auto.shape\n",
    "#for i in range(rows):\n",
    "        #x = []\n",
    "        #for j in range(cols):\n",
    "            #k = gray[i,j]\n",
    "            #print(k)\n",
    "            #x.append(auto[i,j])\n",
    "        #print(x)\n",
    "\n",
    "#cv2.imshow('histogram equalisation', detected)\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "    #args = argparser.parse_args()\n",
    "    #_main_(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
